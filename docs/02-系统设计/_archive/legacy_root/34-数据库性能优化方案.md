# ç½—è±L2Cé”€å”®ç®¡ç†ç³»ç»Ÿ - æ•°æ®åº“æ€§èƒ½ä¼˜åŒ–æ–¹æ¡ˆ

## ğŸ“‹ æ–‡æ¡£æ¦‚è¿°

**é¡¹ç›®åç§°ï¼š** ç½—è±L2Cé”€å”®ç®¡ç†ç³»ç»Ÿæ•°æ®åº“æ€§èƒ½ä¼˜åŒ–æ–¹æ¡ˆ  
**æ–‡æ¡£ç‰ˆæœ¬ï¼š** v1.0  
**åˆ›å»ºæ—¥æœŸï¼š** 2024å¹´  
**è®¾è®¡ç›®æ ‡ï¼š** æ„å»ºé«˜æ€§èƒ½ã€å¯æ‰©å±•çš„æ•°æ®åº“æ¶æ„ï¼Œæå‡ç³»ç»Ÿæ•´ä½“æ€§èƒ½  

---

## ğŸ¯ ä¼˜åŒ–ç›®æ ‡ä¸ä»·å€¼

### 1. æ ¸å¿ƒé—®é¢˜è§£å†³
- **æŸ¥è¯¢æ€§èƒ½ç“¶é¢ˆ**ï¼šå¤æ‚æŸ¥è¯¢å“åº”æ—¶é—´è¿‡é•¿ï¼Œå½±å“ç”¨æˆ·ä½“éªŒ
- **ç´¢å¼•è®¾è®¡ä¸åˆç†**ï¼šç¼ºä¹å¤åˆç´¢å¼•ï¼Œå•å­—æ®µç´¢å¼•æ•ˆç‡ä½ä¸‹
- **æ•°æ®é‡å¢é•¿å‹åŠ›**ï¼šå¤§è¡¨æŸ¥è¯¢æ€§èƒ½ä¸‹é™ï¼Œéœ€è¦åˆ†åŒºç­–ç•¥
- **è¿æ¥æ± é…ç½®ä¸å½“**ï¼šæ•°æ®åº“è¿æ¥èµ„æºæµªè´¹ï¼Œå¹¶å‘æ€§èƒ½å·®
- **æ…¢æŸ¥è¯¢ç›‘æ§ç¼ºå¤±**ï¼šæ— æ³•åŠæ—¶å‘ç°å’Œä¼˜åŒ–æ€§èƒ½é—®é¢˜

### 2. ä¸šåŠ¡ä»·å€¼
- **ç”¨æˆ·ä½“éªŒæå‡**ï¼šæŸ¥è¯¢å“åº”æ—¶é—´ä»ç§’çº§ä¼˜åŒ–åˆ°æ¯«ç§’çº§
- **ç³»ç»Ÿç¨³å®šæ€§å¢å¼º**ï¼šå‡å°‘æ•°æ®åº“å‹åŠ›ï¼Œæé«˜ç³»ç»Ÿå¯ç”¨æ€§
- **è¿ç»´æ•ˆç‡æå‡**ï¼šè‡ªåŠ¨åŒ–ç›‘æ§å’Œä¼˜åŒ–ï¼Œé™ä½è¿ç»´æˆæœ¬
- **ä¸šåŠ¡æ‰©å±•æ”¯æ’‘**ï¼šæ”¯æŒæ›´å¤§æ•°æ®é‡å’Œæ›´é«˜å¹¶å‘è®¿é—®

### 3. æŠ€æœ¯ç›®æ ‡
- **æŸ¥è¯¢æ€§èƒ½**ï¼šå¸¸ç”¨æŸ¥è¯¢å“åº”æ—¶é—´ < 100ms
- **å¹¶å‘èƒ½åŠ›**ï¼šæ”¯æŒ1000+å¹¶å‘è¿æ¥
- **æ•°æ®å®¹é‡**ï¼šæ”¯æŒTBçº§æ•°æ®å­˜å‚¨å’ŒæŸ¥è¯¢
- **å¯ç”¨æ€§**ï¼š99.9%ç³»ç»Ÿå¯ç”¨æ€§ä¿éšœ

---

## ğŸ—ï¸ æ•°æ®åº“æ¶æ„ä¼˜åŒ–

### 1. å¤åˆç´¢å¼•ç­–ç•¥è®¾è®¡

#### 1.1 æ ¸å¿ƒä¸šåŠ¡è¡¨å¤åˆç´¢å¼•

##### 1.1.1 é”€å”®è®¢å•è¡¨ï¼ˆsales_ordersï¼‰å¤åˆç´¢å¼•
```sql
-- è®¢å•çŠ¶æ€æŸ¥è¯¢ä¼˜åŒ–ï¼ˆæœ€é«˜é¢‘ï¼‰
CREATE INDEX idx_sales_orders_status_created ON sales_orders(status, created_at DESC);

-- é”€å”®äººå‘˜è®¢å•æŸ¥è¯¢ä¼˜åŒ–
CREATE INDEX idx_sales_orders_sales_status_created ON sales_orders(sales_id, status, created_at DESC);

-- å®¢æˆ·è®¢å•æŸ¥è¯¢ä¼˜åŒ–
CREATE INDEX idx_sales_orders_customer_status ON sales_orders(customer_id, status, created_at DESC);

-- è®¢å•é‡‘é¢èŒƒå›´æŸ¥è¯¢ä¼˜åŒ–
CREATE INDEX idx_sales_orders_amount_status ON sales_orders(total_amount, status) 
WHERE status NOT IN ('CANCELLED', 'DELETED');

-- è®¢å•ç¼–å·ç²¾ç¡®æŸ¥è¯¢ä¼˜åŒ–
CREATE INDEX idx_sales_orders_order_no ON sales_orders(order_no) 
WHERE order_no IS NOT NULL;

-- å®¢æˆ·å§“åæ¨¡ç³ŠæŸ¥è¯¢ä¼˜åŒ–
CREATE INDEX idx_sales_orders_customer_name_gin ON sales_orders 
USING gin(customer_name gin_trgm_ops);

-- å¤šç»´åº¦ç»„åˆæŸ¥è¯¢ä¼˜åŒ–
CREATE INDEX idx_sales_orders_composite ON sales_orders(
    status, sales_id, created_at DESC, total_amount
) WHERE deleted_at IS NULL;
```

##### 1.1.2 çº¿ç´¢è¡¨ï¼ˆleadsï¼‰å¤åˆç´¢å¼•
```sql
-- çº¿ç´¢åˆ†é…æŸ¥è¯¢ä¼˜åŒ–ï¼ˆæœ€é«˜é¢‘ï¼‰
CREATE INDEX idx_leads_assigned_status_follow ON leads(assigned_to, status, next_follow_time);

-- çº¿ç´¢æ¥æºåˆ†æä¼˜åŒ–
CREATE INDEX idx_leads_source_status_created ON leads(source, status, created_at DESC);

-- çº¿ç´¢è½¬åŒ–åˆ†æä¼˜åŒ–
CREATE INDEX idx_leads_converted_time ON leads(converted_at, converted_to_order_id) 
WHERE status = 'converted';

-- å®¢æˆ·ç”µè¯æŸ¥è¯¢ä¼˜åŒ–
CREATE INDEX idx_leads_customer_phone ON leads(customer_phone) 
WHERE customer_phone IS NOT NULL;

-- è·Ÿè¿›æ—¶é—´æŸ¥è¯¢ä¼˜åŒ–
CREATE INDEX idx_leads_follow_time_status ON leads(next_follow_time, status) 
WHERE status IN ('assigned', 'following');

-- åœ°åŒºåˆ†å¸ƒæŸ¥è¯¢ä¼˜åŒ–
CREATE INDEX idx_leads_city_status_created ON leads(city, status, created_at DESC);

-- çº¿ç´¢æœç´¢ä¼˜åŒ–
CREATE INDEX idx_leads_search_gin ON leads 
USING gin((customer_name || ' ' || COALESCE(customer_phone, '') || ' ' || COALESCE(requirement, '')) gin_trgm_ops);
```

##### 1.1.3 å®¢æˆ·è¡¨ï¼ˆcustomersï¼‰å¤åˆç´¢å¼•
```sql
-- å®¢æˆ·çŠ¶æ€æŸ¥è¯¢ä¼˜åŒ–
CREATE INDEX idx_customers_status_created ON customers(status, created_at DESC);

-- å®¢æˆ·æ¥æºåˆ†æä¼˜åŒ–
CREATE INDEX idx_customers_source_city_status ON customers(source, city, status);

-- å®¢æˆ·ç­‰çº§æŸ¥è¯¢ä¼˜åŒ–
CREATE INDEX idx_customers_level_status ON customers(customer_level, status);

-- å®¢æˆ·ç”µè¯å”¯ä¸€æ€§ä¼˜åŒ–
CREATE UNIQUE INDEX idx_customers_phone_unique ON customers(phone) 
WHERE deleted_at IS NULL;

-- å®¢æˆ·æœç´¢ä¼˜åŒ–
CREATE INDEX idx_customers_search_gin ON customers 
USING gin((customer_name || ' ' || phone || ' ' || COALESCE(company_name, '')) gin_trgm_ops);

-- å®¢æˆ·åœ°åŒºåˆ†å¸ƒä¼˜åŒ–
CREATE INDEX idx_customers_region_status ON customers(province, city, status);
```

##### 1.1.4 ç”¨æˆ·è¡¨ï¼ˆusersï¼‰å¤åˆç´¢å¼•
```sql
-- ç”¨æˆ·ç™»å½•æŸ¥è¯¢ä¼˜åŒ–
CREATE INDEX idx_users_username_status ON users(username, status) 
WHERE deleted_at IS NULL;

-- ç”¨æˆ·è§’è‰²æŸ¥è¯¢ä¼˜åŒ–
CREATE INDEX idx_users_role_dept_status ON users(role, department_id, status);

-- ç”¨æˆ·éƒ¨é—¨æŸ¥è¯¢ä¼˜åŒ–
CREATE INDEX idx_users_dept_status_created ON users(department_id, status, created_at DESC);

-- ç”¨æˆ·æ‰‹æœºå·æŸ¥è¯¢ä¼˜åŒ–
CREATE INDEX idx_users_phone ON users(phone) 
WHERE phone IS NOT NULL AND deleted_at IS NULL;
```

##### 1.1.5 ç§¯åˆ†æµæ°´è¡¨ï¼ˆpoint_logsï¼‰å¤åˆç´¢å¼•
```sql
-- ç”¨æˆ·ç§¯åˆ†æŸ¥è¯¢ä¼˜åŒ–ï¼ˆæœ€é«˜é¢‘ï¼‰
CREATE INDEX idx_point_logs_user_created ON point_logs(user_id, created_at DESC);

-- ç§¯åˆ†ç±»å‹ç»Ÿè®¡ä¼˜åŒ–
CREATE INDEX idx_point_logs_type_source_created ON point_logs(type, source, created_at DESC);

-- ç§¯åˆ†ä¸šåŠ¡å…³è”æŸ¥è¯¢ä¼˜åŒ–
CREATE INDEX idx_point_logs_business ON point_logs(business_type, business_id) 
WHERE business_id IS NOT NULL;

-- ç§¯åˆ†è¿‡æœŸæŸ¥è¯¢ä¼˜åŒ–
CREATE INDEX idx_point_logs_expire_status ON point_logs(expire_at, status) 
WHERE expire_at IS NOT NULL;
```

#### 1.2 ç´¢å¼•ä½¿ç”¨ç›‘æ§å’Œä¼˜åŒ–

##### 1.2.1 ç´¢å¼•ä½¿ç”¨æƒ…å†µç›‘æ§
```sql
-- åˆ›å»ºç´¢å¼•ä½¿ç”¨ç›‘æ§è§†å›¾
CREATE OR REPLACE VIEW v_index_usage_stats AS
SELECT 
    schemaname,
    tablename,
    indexname,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch,
    CASE 
        WHEN idx_scan = 0 THEN 'UNUSED'
        WHEN idx_scan < 100 THEN 'LOW_USAGE'
        WHEN idx_scan < 1000 THEN 'MEDIUM_USAGE'
        ELSE 'HIGH_USAGE'
    END AS usage_level,
    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size
FROM pg_stat_user_indexes 
ORDER BY idx_scan DESC;

-- æŸ¥æ‰¾æœªä½¿ç”¨çš„ç´¢å¼•
SELECT * FROM v_index_usage_stats WHERE usage_level = 'UNUSED';

-- æŸ¥æ‰¾é‡å¤ç´¢å¼•
WITH index_columns AS (
    SELECT 
        schemaname,
        tablename,
        indexname,
        array_agg(attname ORDER BY attnum) AS columns
    FROM pg_indexes 
    JOIN pg_class ON pg_class.relname = indexname
    JOIN pg_index ON pg_index.indexrelid = pg_class.oid
    JOIN pg_attribute ON pg_attribute.attrelid = pg_index.indrelid 
        AND pg_attribute.attnum = ANY(pg_index.indkey)
    WHERE schemaname = 'public'
    GROUP BY schemaname, tablename, indexname
)
SELECT 
    ic1.schemaname,
    ic1.tablename,
    ic1.indexname AS index1,
    ic2.indexname AS index2,
    ic1.columns
FROM index_columns ic1
JOIN index_columns ic2 ON ic1.schemaname = ic2.schemaname 
    AND ic1.tablename = ic2.tablename
    AND ic1.columns = ic2.columns
    AND ic1.indexname < ic2.indexname;
```

##### 1.2.2 ç´¢å¼•ç»´æŠ¤ç­–ç•¥
```sql
-- å®šæœŸé‡å»ºç´¢å¼•ï¼ˆæ¯æœˆæ‰§è¡Œï¼‰
DO $$
DECLARE
    rec RECORD;
BEGIN
    FOR rec IN 
        SELECT schemaname, tablename, indexname 
        FROM pg_stat_user_indexes 
        WHERE idx_scan > 1000  -- åªé‡å»ºé«˜ä½¿ç”¨ç‡çš„ç´¢å¼•
    LOOP
        EXECUTE format('REINDEX INDEX CONCURRENTLY %I.%I', rec.schemaname, rec.indexname);
    END LOOP;
END $$;

-- æ›´æ–°è¡¨ç»Ÿè®¡ä¿¡æ¯ï¼ˆæ¯æ—¥æ‰§è¡Œï¼‰
DO $$
DECLARE
    rec RECORD;
BEGIN
    FOR rec IN 
        SELECT schemaname, tablename 
        FROM pg_stat_user_tables 
        WHERE n_tup_ins + n_tup_upd + n_tup_del > 1000  -- å˜æ›´è¾ƒå¤šçš„è¡¨
    LOOP
        EXECUTE format('ANALYZE %I.%I', rec.schemaname, rec.tablename);
    END LOOP;
END $$;
```

### 2. æ•°æ®åº“åˆ†åŒºç­–ç•¥

#### 2.1 æ—¶é—´åˆ†åŒºç­–ç•¥

##### 2.1.1 è®¢å•è¡¨æŒ‰æœˆåˆ†åŒº
```sql
-- åˆ›å»ºåˆ†åŒºä¸»è¡¨
CREATE TABLE sales_orders_partitioned (
    id BIGSERIAL,
    order_no VARCHAR(50) NOT NULL,
    customer_id BIGINT NOT NULL,
    customer_name VARCHAR(100) NOT NULL,
    sales_id BIGINT NOT NULL,
    status VARCHAR(20) NOT NULL,
    total_amount DECIMAL(12,2) NOT NULL,
    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    deleted_at TIMESTAMP NULL
) PARTITION BY RANGE (created_at);

-- åˆ›å»ºåˆ†åŒºè¡¨ï¼ˆæŒ‰æœˆï¼‰
CREATE TABLE sales_orders_2024_01 PARTITION OF sales_orders_partitioned
    FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');

CREATE TABLE sales_orders_2024_02 PARTITION OF sales_orders_partitioned
    FOR VALUES FROM ('2024-02-01') TO ('2024-03-01');

-- è‡ªåŠ¨åˆ›å»ºåˆ†åŒºçš„å‡½æ•°
CREATE OR REPLACE FUNCTION create_monthly_partition(
    table_name TEXT,
    start_date DATE
) RETURNS VOID AS $$
DECLARE
    partition_name TEXT;
    end_date DATE;
BEGIN
    partition_name := table_name || '_' || to_char(start_date, 'YYYY_MM');
    end_date := start_date + INTERVAL '1 month';
    
    EXECUTE format(
        'CREATE TABLE IF NOT EXISTS %I PARTITION OF %I FOR VALUES FROM (%L) TO (%L)',
        partition_name, table_name, start_date, end_date
    );
    
    -- åˆ›å»ºåˆ†åŒºç´¢å¼•
    EXECUTE format(
        'CREATE INDEX IF NOT EXISTS idx_%s_created_at ON %I (created_at)',
        partition_name, partition_name
    );
    
    EXECUTE format(
        'CREATE INDEX IF NOT EXISTS idx_%s_status ON %I (status)',
        partition_name, partition_name
    );
END;
$$ LANGUAGE plpgsql;

-- å®šæ—¶ä»»åŠ¡ï¼šæ¯æœˆè‡ªåŠ¨åˆ›å»ºä¸‹ä¸ªæœˆçš„åˆ†åŒº
SELECT cron.schedule('create-monthly-partitions', '0 0 1 * *', $$
    SELECT create_monthly_partition('sales_orders_partitioned', date_trunc('month', CURRENT_DATE + INTERVAL '1 month')::date);
    SELECT create_monthly_partition('point_logs_partitioned', date_trunc('month', CURRENT_DATE + INTERVAL '1 month')::date);
$$);
```

##### 2.1.2 æ—¥å¿—è¡¨æŒ‰å‘¨åˆ†åŒº
```sql
-- æ“ä½œæ—¥å¿—è¡¨åˆ†åŒº
CREATE TABLE operation_logs_partitioned (
    id BIGSERIAL,
    user_id BIGINT NOT NULL,
    action VARCHAR(50) NOT NULL,
    resource_type VARCHAR(50) NOT NULL,
    resource_id BIGINT,
    details JSONB,
    ip_address INET,
    user_agent TEXT,
    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP
) PARTITION BY RANGE (created_at);

-- åˆ›å»ºæŒ‰å‘¨åˆ†åŒºçš„å‡½æ•°
CREATE OR REPLACE FUNCTION create_weekly_partition(
    table_name TEXT,
    start_date DATE
) RETURNS VOID AS $$
DECLARE
    partition_name TEXT;
    end_date DATE;
BEGIN
    partition_name := table_name || '_' || to_char(start_date, 'YYYY_WW');
    end_date := start_date + INTERVAL '1 week';
    
    EXECUTE format(
        'CREATE TABLE IF NOT EXISTS %I PARTITION OF %I FOR VALUES FROM (%L) TO (%L)',
        partition_name, table_name, start_date, end_date
    );
    
    -- åˆ›å»ºåˆ†åŒºç´¢å¼•
    EXECUTE format(
        'CREATE INDEX IF NOT EXISTS idx_%s_user_created ON %I (user_id, created_at)',
        partition_name, partition_name
    );
END;
$$ LANGUAGE plpgsql;
```

#### 2.2 æ•°æ®å½’æ¡£ç­–ç•¥

##### 2.2.1 å†å²æ•°æ®å½’æ¡£
```sql
-- åˆ›å»ºå½’æ¡£è¡¨ç»“æ„
CREATE TABLE sales_orders_archive (
    LIKE sales_orders INCLUDING ALL
);

-- æ•°æ®å½’æ¡£å‡½æ•°
CREATE OR REPLACE FUNCTION archive_old_data(
    table_name TEXT,
    archive_table TEXT,
    archive_months INTEGER DEFAULT 12
) RETURNS INTEGER AS $$
DECLARE
    archive_date DATE;
    archived_count INTEGER;
BEGIN
    archive_date := CURRENT_DATE - INTERVAL '1 month' * archive_months;
    
    -- ç§»åŠ¨æ•°æ®åˆ°å½’æ¡£è¡¨
    EXECUTE format(
        'INSERT INTO %I SELECT * FROM %I WHERE created_at < %L',
        archive_table, table_name, archive_date
    );
    
    GET DIAGNOSTICS archived_count = ROW_COUNT;
    
    -- åˆ é™¤åŸè¡¨ä¸­çš„æ—§æ•°æ®
    EXECUTE format(
        'DELETE FROM %I WHERE created_at < %L',
        table_name, archive_date
    );
    
    RETURN archived_count;
END;
$$ LANGUAGE plpgsql;

-- å®šæ—¶å½’æ¡£ä»»åŠ¡ï¼ˆæ¯æœˆæ‰§è¡Œï¼‰
SELECT cron.schedule('archive-old-data', '0 2 1 * *', $$
    SELECT archive_old_data('sales_orders', 'sales_orders_archive', 24);
    SELECT archive_old_data('operation_logs', 'operation_logs_archive', 6);
    SELECT archive_old_data('point_logs', 'point_logs_archive', 36);
$$);
```

##### 2.2.2 æ•°æ®ç”Ÿå‘½å‘¨æœŸç®¡ç†
```sql
-- æ•°æ®ç”Ÿå‘½å‘¨æœŸé…ç½®è¡¨
CREATE TABLE data_lifecycle_policies (
    id SERIAL PRIMARY KEY,
    table_name VARCHAR(100) NOT NULL,
    retention_months INTEGER NOT NULL,
    archive_months INTEGER NOT NULL,
    delete_months INTEGER,
    is_active BOOLEAN DEFAULT true,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- æ’å…¥ç”Ÿå‘½å‘¨æœŸç­–ç•¥
INSERT INTO data_lifecycle_policies (table_name, retention_months, archive_months, delete_months) VALUES
('sales_orders', 24, 12, 60),
('leads', 36, 24, 84),
('operation_logs', 6, 3, 12),
('point_logs', 36, 24, 60),
('notification_send_logs', 3, 1, 6);

-- è‡ªåŠ¨åŒ–æ•°æ®ç”Ÿå‘½å‘¨æœŸç®¡ç†
CREATE OR REPLACE FUNCTION manage_data_lifecycle() RETURNS VOID AS $$
DECLARE
    policy RECORD;
    archive_date DATE;
    delete_date DATE;
BEGIN
    FOR policy IN 
        SELECT * FROM data_lifecycle_policies WHERE is_active = true
    LOOP
        archive_date := CURRENT_DATE - INTERVAL '1 month' * policy.archive_months;
        
        -- æ‰§è¡Œå½’æ¡£
        PERFORM archive_old_data(
            policy.table_name, 
            policy.table_name || '_archive', 
            policy.archive_months
        );
        
        -- æ‰§è¡Œåˆ é™¤ï¼ˆå¦‚æœé…ç½®äº†åˆ é™¤ç­–ç•¥ï¼‰
        IF policy.delete_months IS NOT NULL THEN
            delete_date := CURRENT_DATE - INTERVAL '1 month' * policy.delete_months;
            EXECUTE format(
                'DELETE FROM %I WHERE created_at < %L',
                policy.table_name || '_archive', delete_date
            );
        END IF;
        
        RAISE NOTICE 'Processed lifecycle for table: %', policy.table_name;
    END LOOP;
END;
$$ LANGUAGE plpgsql;
```

### 3. æ…¢æŸ¥è¯¢ç›‘æ§å’Œä¼˜åŒ–

#### 3.1 æ…¢æŸ¥è¯¢ç›‘æ§é…ç½®

##### 3.1.1 PostgreSQLæ…¢æŸ¥è¯¢é…ç½®
```sql
-- å¯ç”¨æ…¢æŸ¥è¯¢æ—¥å¿—
ALTER SYSTEM SET log_min_duration_statement = 1000;  -- è®°å½•è¶…è¿‡1ç§’çš„æŸ¥è¯¢
ALTER SYSTEM SET log_statement = 'all';
ALTER SYSTEM SET log_duration = on;
ALTER SYSTEM SET log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h ';
ALTER SYSTEM SET log_checkpoints = on;
ALTER SYSTEM SET log_connections = on;
ALTER SYSTEM SET log_disconnections = on;
ALTER SYSTEM SET log_lock_waits = on;
ALTER SYSTEM SET log_temp_files = 0;
SELECT pg_reload_conf();

-- åˆ›å»ºæ…¢æŸ¥è¯¢åˆ†æè¡¨
CREATE TABLE slow_query_analysis (
    id BIGSERIAL PRIMARY KEY,
    query_time TIMESTAMP NOT NULL,
    duration_ms DECIMAL(10,3) NOT NULL,
    query_text TEXT NOT NULL,
    query_hash VARCHAR(64) NOT NULL,
    user_name VARCHAR(100),
    database_name VARCHAR(100),
    application_name VARCHAR(100),
    client_addr INET,
    rows_examined BIGINT,
    rows_sent BIGINT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_slow_query_duration ON slow_query_analysis(duration_ms DESC);
CREATE INDEX idx_slow_query_hash ON slow_query_analysis(query_hash);
CREATE INDEX idx_slow_query_time ON slow_query_analysis(query_time);
```

##### 3.1.2 æŸ¥è¯¢æ€§èƒ½ç›‘æ§è§†å›¾
```sql
-- åˆ›å»ºæŸ¥è¯¢æ€§èƒ½ç»Ÿè®¡è§†å›¾
CREATE OR REPLACE VIEW v_query_performance AS
SELECT 
    query,
    calls,
    total_time,
    mean_time,
    min_time,
    max_time,
    stddev_time,
    rows,
    100.0 * shared_blks_hit / nullif(shared_blks_hit + shared_blks_read, 0) AS hit_percent
FROM pg_stat_statements 
ORDER BY total_time DESC;

-- åˆ›å»ºè¡¨çº§æ€§èƒ½ç»Ÿè®¡è§†å›¾
CREATE OR REPLACE VIEW v_table_performance AS
SELECT 
    schemaname,
    tablename,
    seq_scan,
    seq_tup_read,
    idx_scan,
    idx_tup_fetch,
    n_tup_ins,
    n_tup_upd,
    n_tup_del,
    n_tup_hot_upd,
    n_live_tup,
    n_dead_tup,
    last_vacuum,
    last_autovacuum,
    last_analyze,
    last_autoanalyze,
    vacuum_count,
    autovacuum_count,
    analyze_count,
    autoanalyze_count
FROM pg_stat_user_tables
ORDER BY seq_scan + idx_scan DESC;

-- åˆ›å»ºç´¢å¼•æ€§èƒ½ç»Ÿè®¡è§†å›¾
CREATE OR REPLACE VIEW v_index_performance AS
SELECT 
    schemaname,
    tablename,
    indexname,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch,
    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size,
    CASE 
        WHEN idx_scan = 0 THEN 'NEVER_USED'
        WHEN idx_scan < 10 THEN 'RARELY_USED'
        WHEN idx_scan < 100 THEN 'OCCASIONALLY_USED'
        ELSE 'FREQUENTLY_USED'
    END AS usage_frequency
FROM pg_stat_user_indexes
ORDER BY idx_scan DESC;
```

#### 3.2 æŸ¥è¯¢ä¼˜åŒ–å»ºè®®

##### 3.2.1 è‡ªåŠ¨æŸ¥è¯¢ä¼˜åŒ–å»ºè®®
```sql
-- åˆ›å»ºæŸ¥è¯¢ä¼˜åŒ–å»ºè®®å‡½æ•°
CREATE OR REPLACE FUNCTION generate_optimization_suggestions()
RETURNS TABLE(
    suggestion_type TEXT,
    table_name TEXT,
    suggestion TEXT,
    priority INTEGER
) AS $$
BEGIN
    -- å»ºè®®æ·»åŠ ç´¢å¼•ï¼ˆåŸºäºæ…¢æŸ¥è¯¢åˆ†æï¼‰
    RETURN QUERY
    SELECT 
        'ADD_INDEX'::TEXT,
        t.tablename::TEXT,
        format('Consider adding index on table %s for columns frequently used in WHERE clauses', t.tablename)::TEXT,
        1::INTEGER
    FROM pg_stat_user_tables t
    WHERE t.seq_scan > t.idx_scan * 10  -- å…¨è¡¨æ‰«æè¿œå¤šäºç´¢å¼•æ‰«æ
        AND t.n_live_tup > 10000;  -- è¡¨æ•°æ®é‡è¾ƒå¤§

    -- å»ºè®®åˆ é™¤æœªä½¿ç”¨çš„ç´¢å¼•
    RETURN QUERY
    SELECT 
        'DROP_INDEX'::TEXT,
        i.tablename::TEXT,
        format('Consider dropping unused index %s on table %s', i.indexname, i.tablename)::TEXT,
        2::INTEGER
    FROM pg_stat_user_indexes i
    WHERE i.idx_scan = 0
        AND i.indexname NOT LIKE '%_pkey'  -- æ’é™¤ä¸»é”®ç´¢å¼•
        AND i.indexname NOT LIKE '%_unique';  -- æ’é™¤å”¯ä¸€ç´¢å¼•

    -- å»ºè®®æ‰§è¡ŒVACUUM
    RETURN QUERY
    SELECT 
        'VACUUM_TABLE'::TEXT,
        t.tablename::TEXT,
        format('Consider running VACUUM on table %s (dead tuples: %s)', t.tablename, t.n_dead_tup)::TEXT,
        CASE 
            WHEN t.n_dead_tup > t.n_live_tup * 0.2 THEN 1  -- æ­»å…ƒç»„è¶…è¿‡20%ï¼Œé«˜ä¼˜å…ˆçº§
            WHEN t.n_dead_tup > t.n_live_tup * 0.1 THEN 2  -- æ­»å…ƒç»„è¶…è¿‡10%ï¼Œä¸­ä¼˜å…ˆçº§
            ELSE 3  -- ä½ä¼˜å…ˆçº§
        END::INTEGER
    FROM pg_stat_user_tables t
    WHERE t.n_dead_tup > 1000;

    -- å»ºè®®æ‰§è¡ŒANALYZE
    RETURN QUERY
    SELECT 
        'ANALYZE_TABLE'::TEXT,
        t.tablename::TEXT,
        format('Consider running ANALYZE on table %s (last analyze: %s)', t.tablename, t.last_analyze)::TEXT,
        2::INTEGER
    FROM pg_stat_user_tables t
    WHERE t.last_analyze < CURRENT_DATE - INTERVAL '7 days'
        OR t.last_analyze IS NULL;
END;
$$ LANGUAGE plpgsql;

-- æŸ¥çœ‹ä¼˜åŒ–å»ºè®®
SELECT * FROM generate_optimization_suggestions() ORDER BY priority, table_name;
```

### 4. è¿æ¥æ± é…ç½®ä¼˜åŒ–

#### 4.1 è¿æ¥æ± é…ç½®ç­–ç•¥

##### 4.1.1 åº”ç”¨å±‚è¿æ¥æ± é…ç½®ï¼ˆPrismaï¼‰
```typescript
// prisma/schema.prisma
generator client {
  provider = "prisma-client-js"
  previewFeatures = ["metrics"]
}

datasource db {
  provider = "postgresql"
  url      = env("DATABASE_URL")
}

// è¿æ¥æ± é…ç½®
const prisma = new PrismaClient({
  datasources: {
    db: {
      url: process.env.DATABASE_URL + "?connection_limit=20&pool_timeout=20&socket_timeout=60"
    }
  },
  log: [
    { level: 'query', emit: 'event' },
    { level: 'error', emit: 'stdout' },
    { level: 'warn', emit: 'stdout' },
  ],
});

// è¿æ¥æ± ç›‘æ§
prisma.$on('query', (e) => {
  if (e.duration > 1000) {  // è®°å½•è¶…è¿‡1ç§’çš„æŸ¥è¯¢
    console.log('Slow Query:', {
      query: e.query,
      params: e.params,
      duration: e.duration,
      timestamp: e.timestamp
    });
  }
});

// è¿æ¥æ± é…ç½®ç±»
export class DatabaseConfig {
  static getConnectionConfig(env: string) {
    const configs = {
      development: {
        connectionLimit: 10,
        poolTimeout: 20,
        socketTimeout: 60,
        statementTimeout: 30000,
        queryTimeout: 30000,
        connectionTimeoutMillis: 5000,
        idleTimeoutMillis: 30000,
        maxUses: 7500,
        maxLifetime: 600000,  // 10åˆ†é’Ÿ
      },
      production: {
        connectionLimit: 50,
        poolTimeout: 30,
        socketTimeout: 120,
        statementTimeout: 60000,
        queryTimeout: 60000,
        connectionTimeoutMillis: 10000,
        idleTimeoutMillis: 60000,
        maxUses: 7500,
        maxLifetime: 1800000,  // 30åˆ†é’Ÿ
      }
    };
    
    return configs[env] || configs.development;
  }
}
```

##### 4.1.2 æ•°æ®åº“æœåŠ¡å™¨è¿æ¥é…ç½®
```sql
-- PostgreSQLè¿æ¥é…ç½®ä¼˜åŒ–
ALTER SYSTEM SET max_connections = 200;
ALTER SYSTEM SET shared_buffers = '256MB';
ALTER SYSTEM SET effective_cache_size = '1GB';
ALTER SYSTEM SET maintenance_work_mem = '64MB';
ALTER SYSTEM SET checkpoint_completion_target = 0.9;
ALTER SYSTEM SET wal_buffers = '16MB';
ALTER SYSTEM SET default_statistics_target = 100;
ALTER SYSTEM SET random_page_cost = 1.1;
ALTER SYSTEM SET effective_io_concurrency = 200;

-- è¿æ¥è¶…æ—¶é…ç½®
ALTER SYSTEM SET statement_timeout = '60s';
ALTER SYSTEM SET lock_timeout = '30s';
ALTER SYSTEM SET idle_in_transaction_session_timeout = '60s';
ALTER SYSTEM SET tcp_keepalives_idle = 600;
ALTER SYSTEM SET tcp_keepalives_interval = 30;
ALTER SYSTEM SET tcp_keepalives_count = 3;

SELECT pg_reload_conf();

-- åˆ›å»ºè¿æ¥ç›‘æ§è§†å›¾
CREATE OR REPLACE VIEW v_connection_stats AS
SELECT 
    datname,
    usename,
    application_name,
    client_addr,
    state,
    COUNT(*) as connection_count,
    MAX(now() - backend_start) as max_connection_age,
    MAX(now() - state_change) as max_state_duration
FROM pg_stat_activity 
WHERE state IS NOT NULL
GROUP BY datname, usename, application_name, client_addr, state
ORDER BY connection_count DESC;

-- è¿æ¥æ± ä½¿ç”¨æƒ…å†µç›‘æ§
CREATE OR REPLACE FUNCTION monitor_connection_pool()
RETURNS TABLE(
    metric_name TEXT,
    metric_value NUMERIC,
    threshold NUMERIC,
    status TEXT
) AS $$
BEGIN
    -- æ€»è¿æ¥æ•°
    RETURN QUERY
    SELECT 
        'total_connections'::TEXT,
        COUNT(*)::NUMERIC,
        200::NUMERIC,  -- max_connections
        CASE WHEN COUNT(*) > 160 THEN 'WARNING' ELSE 'OK' END::TEXT
    FROM pg_stat_activity;
    
    -- æ´»è·ƒè¿æ¥æ•°
    RETURN QUERY
    SELECT 
        'active_connections'::TEXT,
        COUNT(*)::NUMERIC,
        100::NUMERIC,
        CASE WHEN COUNT(*) > 80 THEN 'WARNING' ELSE 'OK' END::TEXT
    FROM pg_stat_activity 
    WHERE state = 'active';
    
    -- ç©ºé—²è¿æ¥æ•°
    RETURN QUERY
    SELECT 
        'idle_connections'::TEXT,
        COUNT(*)::NUMERIC,
        50::NUMERIC,
        CASE WHEN COUNT(*) > 40 THEN 'WARNING' ELSE 'OK' END::TEXT
    FROM pg_stat_activity 
    WHERE state = 'idle';
    
    -- é•¿æ—¶é—´è¿è¡Œçš„æŸ¥è¯¢
    RETURN QUERY
    SELECT 
        'long_running_queries'::TEXT,
        COUNT(*)::NUMERIC,
        5::NUMERIC,
        CASE WHEN COUNT(*) > 3 THEN 'WARNING' ELSE 'OK' END::TEXT
    FROM pg_stat_activity 
    WHERE state = 'active' 
        AND now() - query_start > INTERVAL '30 seconds';
END;
$$ LANGUAGE plpgsql;
```

#### 4.2 è¿æ¥æ± ç›‘æ§å’Œå‘Šè­¦

##### 4.2.1 è¿æ¥æ± ç›‘æ§è„šæœ¬
```bash
#!/bin/bash
# è¿æ¥æ± ç›‘æ§è„šæœ¬

DB_HOST="localhost"
DB_PORT="5432"
DB_NAME="crm_db"
DB_USER="postgres"

# æ£€æŸ¥è¿æ¥æ± çŠ¶æ€
check_connection_pool() {
    echo "=== è¿æ¥æ± çŠ¶æ€æ£€æŸ¥ ==="
    
    # æ€»è¿æ¥æ•°
    total_connections=$(psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME -t -c "SELECT COUNT(*) FROM pg_stat_activity;")
    echo "æ€»è¿æ¥æ•°: $total_connections"
    
    # æ´»è·ƒè¿æ¥æ•°
    active_connections=$(psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME -t -c "SELECT COUNT(*) FROM pg_stat_activity WHERE state = 'active';")
    echo "æ´»è·ƒè¿æ¥æ•°: $active_connections"
    
    # ç©ºé—²è¿æ¥æ•°
    idle_connections=$(psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME -t -c "SELECT COUNT(*) FROM pg_stat_activity WHERE state = 'idle';")
    echo "ç©ºé—²è¿æ¥æ•°: $idle_connections"
    
    # é•¿æ—¶é—´è¿è¡Œçš„æŸ¥è¯¢
    long_queries=$(psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME -t -c "SELECT COUNT(*) FROM pg_stat_activity WHERE state = 'active' AND now() - query_start > INTERVAL '30 seconds';")
    echo "é•¿æ—¶é—´è¿è¡ŒæŸ¥è¯¢æ•°: $long_queries"
    
    # æ£€æŸ¥å‘Šè­¦æ¡ä»¶
    if [ $total_connections -gt 160 ]; then
        echo "âš ï¸  è­¦å‘Š: æ€»è¿æ¥æ•°è¿‡é«˜ ($total_connections > 160)"
    fi
    
    if [ $active_connections -gt 80 ]; then
        echo "âš ï¸  è­¦å‘Š: æ´»è·ƒè¿æ¥æ•°è¿‡é«˜ ($active_connections > 80)"
    fi
    
    if [ $long_queries -gt 3 ]; then
        echo "âš ï¸  è­¦å‘Š: é•¿æ—¶é—´è¿è¡ŒæŸ¥è¯¢è¿‡å¤š ($long_queries > 3)"
    fi
}

# ä¼˜åŒ–è¿æ¥æ± 
optimize_connection_pool() {
    echo "=== è¿æ¥æ± ä¼˜åŒ– ==="
    
    # ç»ˆæ­¢ç©ºé—²æ—¶é—´è¿‡é•¿çš„è¿æ¥
    psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME -c "
        SELECT pg_terminate_backend(pid) 
        FROM pg_stat_activity 
        WHERE state = 'idle' 
            AND now() - state_change > INTERVAL '10 minutes'
            AND usename != 'postgres';
    "
    
    # ç»ˆæ­¢é•¿æ—¶é—´è¿è¡Œçš„æŸ¥è¯¢
    psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME -c "
        SELECT pg_cancel_backend(pid) 
        FROM pg_stat_activity 
        WHERE state = 'active' 
            AND now() - query_start > INTERVAL '5 minutes'
            AND usename != 'postgres';
    "
    
    echo "è¿æ¥æ± ä¼˜åŒ–å®Œæˆ"
}

# ç”Ÿæˆè¿æ¥æ± æŠ¥å‘Š
generate_connection_report() {
    local output_file="connection_pool_report_$(date +%Y%m%d_%H%M%S).txt"
    
    echo "=== è¿æ¥æ± è¯¦ç»†æŠ¥å‘Š ===" > $output_file
    echo "ç”Ÿæˆæ—¶é—´: $(date)" >> $output_file
    echo "" >> $output_file
    
    echo "=== è¿æ¥ç»Ÿè®¡ ===" >> $output_file
    psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME -c "SELECT * FROM v_connection_stats;" >> $output_file
    
    echo "" >> $output_file
    echo "=== è¿æ¥æ± ç›‘æ§æŒ‡æ ‡ ===" >> $output_file
    psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME -c "SELECT * FROM monitor_connection_pool();" >> $output_file
    
    echo "" >> $output_file
    echo "=== å½“å‰æ´»è·ƒæŸ¥è¯¢ ===" >> $output_file
    psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME -c "
        SELECT pid, usename, application_name, client_addr, state, 
               now() - query_start as duration, query 
        FROM pg_stat_activity 
        WHERE state = 'active' 
        ORDER BY query_start;
    " >> $output_file
    
    echo "è¿æ¥æ± æŠ¥å‘Šå·²ç”Ÿæˆ: $output_file"
}

# ä¸»å‡½æ•°
main() {
    case "$1" in
        "check")
            check_connection_pool
            ;;
        "optimize")
            optimize_connection_pool
            ;;
        "report")
            generate_connection_report
            ;;
        *)
            echo "Usage: $0 {check|optimize|report}"
            echo ""
            echo "Commands:"
            echo "  check    - æ£€æŸ¥è¿æ¥æ± çŠ¶æ€"
            echo "  optimize - ä¼˜åŒ–è¿æ¥æ± "
            echo "  report   - ç”Ÿæˆè¿æ¥æ± æŠ¥å‘Š"
            exit 1
            ;;
    esac
}

main "$@"
```

### 5. è¯»å†™åˆ†ç¦»æ¶æ„è®¾è®¡

#### 5.1 ä¸»ä»å¤åˆ¶é…ç½®

##### 5.1.1 PostgreSQLä¸»ä»å¤åˆ¶è®¾ç½®
```bash
# ä¸»åº“é…ç½® (postgresql.conf)
wal_level = replica
max_wal_senders = 10
max_replication_slots = 10
synchronous_commit = on
archive_mode = on
archive_command = 'cp %p /var/lib/postgresql/archive/%f'

# ä¸»åº“è®¤è¯é…ç½® (pg_hba.conf)
host replication replicator 192.168.1.0/24 md5

# åˆ›å»ºå¤åˆ¶ç”¨æˆ·
CREATE USER replicator REPLICATION LOGIN CONNECTION LIMIT 5 ENCRYPTED PASSWORD 'replica_password';

# ä»åº“é…ç½® (postgresql.conf)
hot_standby = on
max_standby_streaming_delay = 30s
max_standby_archive_delay = 60s
hot_standby_feedback = on

# ä»åº“æ¢å¤é…ç½® (recovery.conf)
standby_mode = 'on'
primary_conninfo = 'host=192.168.1.10 port=5432 user=replicator password=replica_password'
recovery_target_timeline = 'latest'
```

##### 5.1.2 è¯»å†™åˆ†ç¦»ä¸­é—´ä»¶é…ç½®
```typescript
// æ•°æ®åº“è¿æ¥é…ç½®
export class DatabaseConnectionManager {
  private masterConnection: PrismaClient;
  private slaveConnections: PrismaClient[];
  private currentSlaveIndex: number = 0;

  constructor() {
    // ä¸»åº“è¿æ¥ï¼ˆå†™æ“ä½œï¼‰
    this.masterConnection = new PrismaClient({
      datasources: {
        db: {
          url: process.env.DATABASE_MASTER_URL
        }
      }
    });

    // ä»åº“è¿æ¥ï¼ˆè¯»æ“ä½œï¼‰
    this.slaveConnections = [
      new PrismaClient({
        datasources: {
          db: {
            url: process.env.DATABASE_SLAVE1_URL
          }
        }
      }),
      new PrismaClient({
        datasources: {
          db: {
            url: process.env.DATABASE_SLAVE2_URL
          }
        }
      })
    ];
  }

  // è·å–å†™è¿æ¥ï¼ˆä¸»åº“ï¼‰
  getWriteConnection(): PrismaClient {
    return this.masterConnection;
  }

  // è·å–è¯»è¿æ¥ï¼ˆä»åº“ï¼Œè´Ÿè½½å‡è¡¡ï¼‰
  getReadConnection(): PrismaClient {
    const connection = this.slaveConnections[this.currentSlaveIndex];
    this.currentSlaveIndex = (this.currentSlaveIndex + 1) % this.slaveConnections.length;
    return connection;
  }

  // å¥åº·æ£€æŸ¥
  async checkHealth(): Promise<{master: boolean, slaves: boolean[]}> {
    const masterHealth = await this.checkConnectionHealth(this.masterConnection);
    const slavesHealth = await Promise.all(
      this.slaveConnections.map(conn => this.checkConnectionHealth(conn))
    );

    return {
      master: masterHealth,
      slaves: slavesHealth
    };
  }

  private async checkConnectionHealth(connection: PrismaClient): Promise<boolean> {
    try {
      await connection.$queryRaw`SELECT 1`;
      return true;
    } catch (error) {
      console.error('Database connection health check failed:', error);
      return false;
    }
  }
}

// æ•°æ®è®¿é—®å±‚è£…é¥°å™¨
export function ReadWriteSplit(forceWrite: boolean = false) {
  return function (target: any, propertyName: string, descriptor: PropertyDescriptor) {
    const method = descriptor.value;

    descriptor.value = async function (...args: any[]) {
      const dbManager = new DatabaseConnectionManager();
      
      // åˆ¤æ–­æ˜¯å¦ä¸ºå†™æ“ä½œ
      const isWriteOperation = forceWrite || 
        propertyName.includes('create') || 
        propertyName.includes('update') || 
        propertyName.includes('delete') || 
        propertyName.includes('upsert');

      const connection = isWriteOperation ? 
        dbManager.getWriteConnection() : 
        dbManager.getReadConnection();

      // æ›¿æ¢æ–¹æ³•ä¸­çš„æ•°æ®åº“è¿æ¥
      const originalPrisma = this.prisma;
      this.prisma = connection;

      try {
        return await method.apply(this, args);
      } finally {
        this.prisma = originalPrisma;
      }
    };
  };
}
```

#### 5.2 è¯»å†™åˆ†ç¦»å®ç°

##### 5.2.1 æœåŠ¡å±‚è¯»å†™åˆ†ç¦»
```typescript
// ç”¨æˆ·æœåŠ¡ç¤ºä¾‹
export class UserService {
  constructor(private dbManager: DatabaseConnectionManager) {}

  // è¯»æ“ä½œ - ä½¿ç”¨ä»åº“
  @ReadWriteSplit(false)
  async getUserById(id: number): Promise<User | null> {
    return await this.prisma.user.findUnique({
      where: { id }
    });
  }

  // è¯»æ“ä½œ - ä½¿ç”¨ä»åº“
  @ReadWriteSplit(false)
  async getUserList(params: GetUserListParams): Promise<User[]> {
    return await this.prisma.user.findMany({
      where: params.where,
      orderBy: params.orderBy,
      skip: params.skip,
      take: params.take
    });
  }

  // å†™æ“ä½œ - ä½¿ç”¨ä¸»åº“
  @ReadWriteSplit(true)
  async createUser(data: CreateUserData): Promise<User> {
    return await this.prisma.user.create({
      data
    });
  }

  // å†™æ“ä½œ - ä½¿ç”¨ä¸»åº“
  @ReadWriteSplit(true)
  async updateUser(id: number, data: UpdateUserData): Promise<User> {
    return await this.prisma.user.update({
      where: { id },
      data
    });
  }

  // å¼ºåˆ¶ä½¿ç”¨ä¸»åº“çš„è¯»æ“ä½œï¼ˆç¡®ä¿æ•°æ®ä¸€è‡´æ€§ï¼‰
  @ReadWriteSplit(true)
  async getUserForUpdate(id: number): Promise<User | null> {
    return await this.prisma.user.findUnique({
      where: { id }
    });
  }
}
```

##### 5.2.2 æ•°æ®ä¸€è‡´æ€§å¤„ç†
```typescript
// æ•°æ®ä¸€è‡´æ€§ç®¡ç†å™¨
export class DataConsistencyManager {
  private replicationLag: Map<string, number> = new Map();
  
  // æ£€æŸ¥å¤åˆ¶å»¶è¿Ÿ
  async checkReplicationLag(): Promise<void> {
    const masterConnection = this.dbManager.getWriteConnection();
    const slaveConnections = this.dbManager.getSlaveConnections();

    // è·å–ä¸»åº“LSN
    const masterLSN = await masterConnection.$queryRaw<[{lsn: string}]>`
      SELECT pg_current_wal_lsn() as lsn
    `;

    // æ£€æŸ¥å„ä»åº“å»¶è¿Ÿ
    for (let i = 0; i < slaveConnections.length; i++) {
      try {
        const slaveLSN = await slaveConnections[i].$queryRaw<[{lsn: string, lag: number}]>`
          SELECT 
            pg_last_wal_receive_lsn() as lsn,
            EXTRACT(EPOCH FROM (now() - pg_last_xact_replay_timestamp())) as lag
        `;
        
        this.replicationLag.set(`slave_${i}`, slaveLSN[0].lag);
      } catch (error) {
        console.error(`Failed to check replication lag for slave ${i}:`, error);
        this.replicationLag.set(`slave_${i}`, Infinity);
      }
    }
  }

  // è·å–æœ€ä½³è¯»åº“
  getBestReadConnection(): PrismaClient {
    let bestSlave = 0;
    let minLag = Infinity;

    this.replicationLag.forEach((lag, key) => {
      if (key.startsWith('slave_') && lag < minLag) {
        minLag = lag;
        bestSlave = parseInt(key.split('_')[1]);
      }
    });

    return this.dbManager.getSlaveConnection(bestSlave);
  }

  // å¼ºåˆ¶è¯»ä¸»åº“ï¼ˆç¡®ä¿å¼ºä¸€è‡´æ€§ï¼‰
  @ReadWriteSplit(true)
  async readFromMaster<T>(operation: () => Promise<T>): Promise<T> {
    return await operation();
  }
}
```

### 6. æ€§èƒ½ç›‘æ§å’Œå‘Šè­¦

#### 6.1 æ•°æ®åº“æ€§èƒ½æŒ‡æ ‡ç›‘æ§

##### 6.1.1 å…³é”®æ€§èƒ½æŒ‡æ ‡ï¼ˆKPIï¼‰
```sql
-- åˆ›å»ºæ€§èƒ½ç›‘æ§è§†å›¾
CREATE OR REPLACE VIEW v_database_performance_kpi AS
SELECT 
    'query_performance' as metric_category,
    json_build_object(
        'avg_query_time', ROUND(AVG(mean_time), 2),
        'max_query_time', ROUND(MAX(max_time), 2),
        'total_queries', SUM(calls),
        'slow_queries', COUNT(*) FILTER (WHERE mean_time > 1000)
    ) as metrics
FROM pg_stat_statements
UNION ALL
SELECT 
    'connection_performance' as metric_category,
    json_build_object(
        'total_connections', COUNT(*),
        'active_connections', COUNT(*) FILTER (WHERE state = 'active'),
        'idle_connections', COUNT(*) FILTER (WHERE state = 'idle'),
        'waiting_connections', COUNT(*) FILTER (WHERE wait_event IS NOT NULL)
    ) as metrics
FROM pg_stat_activity
UNION ALL
SELECT 
    'cache_performance' as metric_category,
    json_build_object(
        'cache_hit_ratio', ROUND(
            100.0 * sum(blks_hit) / NULLIF(sum(blks_hit) + sum(blks_read), 0), 2
        ),
        'buffer_cache_hit_ratio', ROUND(
            100.0 * (SELECT sum(heap_blks_hit) FROM pg_statio_user_tables) / 
            NULLIF((SELECT sum(heap_blks_hit) + sum(heap_blks_read) FROM pg_statio_user_tables), 0), 2
        )
    ) as metrics
FROM pg_stat_database;

-- æ€§èƒ½å‘Šè­¦è§„åˆ™è¡¨
CREATE TABLE performance_alert_rules (
    id SERIAL PRIMARY KEY,
    rule_name VARCHAR(100) NOT NULL,
    metric_name VARCHAR(100) NOT NULL,
    threshold_value DECIMAL(10,2) NOT NULL,
    comparison_operator VARCHAR(10) NOT NULL, -- '>', '<', '>=', '<=', '='
    alert_level VARCHAR(20) NOT NULL, -- 'INFO', 'WARNING', 'CRITICAL'
    is_active BOOLEAN DEFAULT true,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- æ’å…¥å‘Šè­¦è§„åˆ™
INSERT INTO performance_alert_rules (rule_name, metric_name, threshold_value, comparison_operator, alert_level) VALUES
('æ…¢æŸ¥è¯¢å‘Šè­¦', 'avg_query_time', 1000, '>', 'WARNING'),
('è¿æ¥æ•°å‘Šè­¦', 'total_connections', 160, '>', 'WARNING'),
('ç¼“å­˜å‘½ä¸­ç‡å‘Šè­¦', 'cache_hit_ratio', 95, '<', 'WARNING'),
('æ´»è·ƒè¿æ¥æ•°å‘Šè­¦', 'active_connections', 80, '>', 'CRITICAL'),
('ç­‰å¾…è¿æ¥æ•°å‘Šè­¦', 'waiting_connections', 10, '>', 'WARNING');
```

##### 6.1.2 è‡ªåŠ¨åŒ–æ€§èƒ½ç›‘æ§
```typescript
// æ€§èƒ½ç›‘æ§æœåŠ¡
export class DatabasePerformanceMonitor {
  private alertThresholds = {
    avgQueryTime: 1000, // ms
    maxConnections: 160,
    cacheHitRatio: 95, // %
    replicationLag: 5 // seconds
  };

  async monitorPerformance(): Promise<void> {
    try {
      const metrics = await this.collectMetrics();
      await this.checkAlerts(metrics);
      await this.saveMetrics(metrics);
    } catch (error) {
      console.error('Performance monitoring failed:', error);
    }
  }

  private async collectMetrics(): Promise<PerformanceMetrics> {
    const dbManager = new DatabaseConnectionManager();
    const connection = dbManager.getReadConnection();

    const [queryStats, connectionStats, cacheStats] = await Promise.all([
      this.getQueryStats(connection),
      this.getConnectionStats(connection),
      this.getCacheStats(connection)
    ]);

    return {
      timestamp: new Date(),
      queryStats,
      connectionStats,
      cacheStats
    };
  }

  private async getQueryStats(connection: PrismaClient) {
    const result = await connection.$queryRaw<any[]>`
      SELECT 
        ROUND(AVG(mean_time), 2) as avg_query_time,
        ROUND(MAX(max_time), 2) as max_query_time,
        SUM(calls) as total_queries,
        COUNT(*) FILTER (WHERE mean_time > 1000) as slow_queries
      FROM pg_stat_statements
    `;
    return result[0];
  }

  private async getConnectionStats(connection: PrismaClient) {
    const result = await connection.$queryRaw<any[]>`
      SELECT 
        COUNT(*) as total_connections,
        COUNT(*) FILTER (WHERE state = 'active') as active_connections,
        COUNT(*) FILTER (WHERE state = 'idle') as idle_connections,
        COUNT(*) FILTER (WHERE wait_event IS NOT NULL) as waiting_connections
      FROM pg_stat_activity
    `;
    return result[0];
  }

  private async getCacheStats(connection: PrismaClient) {
    const result = await connection.$queryRaw<any[]>`
      SELECT 
        ROUND(100.0 * sum(blks_hit) / NULLIF(sum(blks_hit) + sum(blks_read), 0), 2) as cache_hit_ratio
      FROM pg_stat_database
    `;
    return result[0];
  }

  private async checkAlerts(metrics: PerformanceMetrics): Promise<void> {
    const alerts: Alert[] = [];

    // æ£€æŸ¥æŸ¥è¯¢æ€§èƒ½
    if (metrics.queryStats.avg_query_time > this.alertThresholds.avgQueryTime) {
      alerts.push({
        level: 'WARNING',
        message: `å¹³å‡æŸ¥è¯¢æ—¶é—´è¿‡é«˜: ${metrics.queryStats.avg_query_time}ms`,
        metric: 'avg_query_time',
        value: metrics.queryStats.avg_query_time,
        threshold: this.alertThresholds.avgQueryTime
      });
    }

    // æ£€æŸ¥è¿æ¥æ•°
    if (metrics.connectionStats.total_connections > this.alertThresholds.maxConnections) {
      alerts.push({
        level: 'WARNING',
        message: `æ•°æ®åº“è¿æ¥æ•°è¿‡é«˜: ${metrics.connectionStats.total_connections}`,
        metric: 'total_connections',
        value: metrics.connectionStats.total_connections,
        threshold: this.alertThresholds.maxConnections
      });
    }

    // æ£€æŸ¥ç¼“å­˜å‘½ä¸­ç‡
    if (metrics.cacheStats.cache_hit_ratio < this.alertThresholds.cacheHitRatio) {
      alerts.push({
        level: 'WARNING',
        message: `ç¼“å­˜å‘½ä¸­ç‡è¿‡ä½: ${metrics.cacheStats.cache_hit_ratio}%`,
        metric: 'cache_hit_ratio',
        value: metrics.cacheStats.cache_hit_ratio,
        threshold: this.alertThresholds.cacheHitRatio
      });
    }

    // å‘é€å‘Šè­¦
    if (alerts.length > 0) {
      await this.sendAlerts(alerts);
    }
  }

  private async sendAlerts(alerts: Alert[]): Promise<void> {
    // å‘é€é‚®ä»¶å‘Šè­¦
    // å‘é€é’‰é’‰/ä¼ä¸šå¾®ä¿¡å‘Šè­¦
    // è®°å½•å‘Šè­¦æ—¥å¿—
    console.log('Performance alerts:', alerts);
  }

  private async saveMetrics(metrics: PerformanceMetrics): Promise<void> {
    // ä¿å­˜åˆ°æ—¶åºæ•°æ®åº“æˆ–ç›‘æ§ç³»ç»Ÿ
    // ä¾‹å¦‚ï¼šInfluxDB, Prometheusç­‰
  }
}

// å®šæ—¶æ‰§è¡Œæ€§èƒ½ç›‘æ§
setInterval(async () => {
  const monitor = new DatabasePerformanceMonitor();
  await monitor.monitorPerformance();
}, 60000); // æ¯åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡
```

### 7. è¿ç»´è„šæœ¬å’Œå·¥å…·

#### 7.1 æ•°æ®åº“ç»´æŠ¤è„šæœ¬
```bash
#!/bin/bash
# æ•°æ®åº“ç»´æŠ¤è„šæœ¬é›†åˆ

DB_HOST="localhost"
DB_PORT="5432"
DB_NAME="crm_db"
DB_USER="postgres"

# æ•°æ®åº“å¥åº·æ£€æŸ¥
health_check() {
    echo "=== æ•°æ®åº“å¥åº·æ£€æŸ¥ ==="
    
    # æ£€æŸ¥æ•°æ®åº“è¿æ¥
    if psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME -c "SELECT 1;" > /dev/null 2>&1; then
        echo "âœ… æ•°æ®åº“è¿æ¥æ­£å¸¸"
    else
        echo "âŒ æ•°æ®åº“è¿æ¥å¤±è´¥"
        exit 1
    fi
    
    # æ£€æŸ¥å¤åˆ¶çŠ¶æ€
    echo "æ£€æŸ¥ä¸»ä»å¤åˆ¶çŠ¶æ€..."
    psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME -c "
        SELECT 
            client_addr,
            state,
            sent_lsn,
            write_lsn,
            flush_lsn,
            replay_lsn,
            write_lag,
            flush_lag,
            replay_lag
        FROM pg_stat_replication;
    "
    
    # æ£€æŸ¥è¡¨ç©ºé—´ä½¿ç”¨æƒ…å†µ
    echo "æ£€æŸ¥è¡¨ç©ºé—´ä½¿ç”¨æƒ…å†µ..."
    psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME -c "
        SELECT 
            schemaname,
            tablename,
            pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size
        FROM pg_tables 
        WHERE schemaname = 'public'
        ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
        LIMIT 10;
    "
}

# æ€§èƒ½ä¼˜åŒ–
performance_optimization() {
    echo "=== æ‰§è¡Œæ€§èƒ½ä¼˜åŒ– ==="
    
    # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
    echo "æ›´æ–°è¡¨ç»Ÿè®¡ä¿¡æ¯..."
    psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME -c "
        DO \$\$
        DECLARE
            rec RECORD;
        BEGIN
            FOR rec IN 
                SELECT schemaname, tablename 
                FROM pg_stat_user_tables 
                WHERE n_tup_ins + n_tup_upd + n_tup_del > 100
            LOOP
                EXECUTE format('ANALYZE %I.%I', rec.schemaname, rec.tablename);
                RAISE NOTICE 'Analyzed table: %.%', rec.schemaname, rec.tablename;
            END LOOP;
        END \$\$;
    "
    
    # æ¸…ç†æ­»å…ƒç»„
    echo "æ¸…ç†æ­»å…ƒç»„..."
    psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME -c "
        DO \$\$
        DECLARE
            rec RECORD;
        BEGIN
            FOR rec IN 
                SELECT schemaname, tablename 
                FROM pg_stat_user_tables 
                WHERE n_dead_tup > n_live_tup * 0.1
            LOOP
                EXECUTE format('VACUUM ANALYZE %I.%I', rec.schemaname, rec.tablename);
                RAISE NOTICE 'Vacuumed table: %.%', rec.schemaname, rec.tablename;
            END LOOP;
        END \$\$;
    "
    
    # é‡å»ºç´¢å¼•ï¼ˆå¦‚æœéœ€è¦ï¼‰
    echo "æ£€æŸ¥å¹¶é‡å»ºç¢ç‰‡åŒ–çš„ç´¢å¼•..."
    psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME -c "
        SELECT 
            schemaname,
            tablename,
            indexname,
            pg_size_pretty(pg_relation_size(indexrelid)) as index_size
        FROM pg_stat_user_indexes 
        WHERE idx_scan > 1000
        ORDER BY pg_relation_size(indexrelid) DESC;
    "
}

# å¤‡ä»½æ•°æ®åº“
backup_database() {
    local backup_dir="/var/backups/postgresql"
    local backup_file="$backup_dir/crm_db_$(date +%Y%m%d_%H%M%S).sql"
    
    echo "=== å¤‡ä»½æ•°æ®åº“ ==="
    
    # åˆ›å»ºå¤‡ä»½ç›®å½•
    mkdir -p $backup_dir
    
    # æ‰§è¡Œå¤‡ä»½
    pg_dump -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME > $backup_file
    
    if [ $? -eq 0 ]; then
        echo "âœ… æ•°æ®åº“å¤‡ä»½æˆåŠŸ: $backup_file"
        
        # å‹ç¼©å¤‡ä»½æ–‡ä»¶
        gzip $backup_file
        echo "âœ… å¤‡ä»½æ–‡ä»¶å·²å‹ç¼©: $backup_file.gz"
        
        # æ¸…ç†7å¤©å‰çš„å¤‡ä»½
        find $backup_dir -name "*.sql.gz" -mtime +7 -delete
        echo "âœ… å·²æ¸…ç†7å¤©å‰çš„å¤‡ä»½æ–‡ä»¶"
    else
        echo "âŒ æ•°æ®åº“å¤‡ä»½å¤±è´¥"
        exit 1
    fi
}

# ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
generate_performance_report() {
    local report_file="performance_report_$(date +%Y%m%d_%H%M%S).html"
    
    echo "=== ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š ==="
    
    cat > $report_file << EOF
<!DOCTYPE html>
<html>
<head>
    <title>æ•°æ®åº“æ€§èƒ½æŠ¥å‘Š</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        table { border-collapse: collapse; width: 100%; margin: 20px 0; }
        th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
        th { background-color: #f2f2f2; }
        .warning { color: orange; }
        .critical { color: red; }
    </style>
</head>
<body>
    <h1>æ•°æ®åº“æ€§èƒ½æŠ¥å‘Š</h1>
    <p>ç”Ÿæˆæ—¶é—´: $(date)</p>
    
    <h2>æŸ¥è¯¢æ€§èƒ½ç»Ÿè®¡</h2>
    <table>
        <tr><th>æŒ‡æ ‡</th><th>å€¼</th></tr>
EOF

    # æ·»åŠ æŸ¥è¯¢æ€§èƒ½æ•°æ®
    psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME -t -c "
        SELECT 
            '<tr><td>å¹³å‡æŸ¥è¯¢æ—¶é—´</td><td>' || ROUND(AVG(mean_time), 2) || ' ms</td></tr>' ||
            '<tr><td>æœ€å¤§æŸ¥è¯¢æ—¶é—´</td><td>' || ROUND(MAX(max_time), 2) || ' ms</td></tr>' ||
            '<tr><td>æ€»æŸ¥è¯¢æ¬¡æ•°</td><td>' || SUM(calls) || '</td></tr>' ||
            '<tr><td>æ…¢æŸ¥è¯¢æ•°é‡</td><td>' || COUNT(*) FILTER (WHERE mean_time > 1000) || '</td></tr>'
        FROM pg_stat_statements;
    " >> $report_file

    cat >> $report_file << EOF
    </table>
    
    <h2>è¿æ¥ç»Ÿè®¡</h2>
    <table>
        <tr><th>è¿æ¥çŠ¶æ€</th><th>æ•°é‡</th></tr>
EOF

    # æ·»åŠ è¿æ¥ç»Ÿè®¡æ•°æ®
    psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME -t -c "
        SELECT 
            '<tr><td>æ€»è¿æ¥æ•°</td><td>' || COUNT(*) || '</td></tr>' ||
            '<tr><td>æ´»è·ƒè¿æ¥</td><td>' || COUNT(*) FILTER (WHERE state = 'active') || '</td></tr>' ||
            '<tr><td>ç©ºé—²è¿æ¥</td><td>' || COUNT(*) FILTER (WHERE state = 'idle') || '</td></tr>'
        FROM pg_stat_activity;
    " >> $report_file

    cat >> $report_file << EOF
    </table>
</body>
</html>
EOF

    echo "âœ… æ€§èƒ½æŠ¥å‘Šå·²ç”Ÿæˆ: $report_file"
}

# ä¸»å‡½æ•°
main() {
    case "$1" in
        "health")
            health_check
            ;;
        "optimize")
            performance_optimization
            ;;
        "backup")
            backup_database
            ;;
        "report")
            generate_performance_report
            ;;
        "all")
            health_check
            performance_optimization
            backup_database
            generate_performance_report
            ;;
        *)
            echo "Usage: $0 {health|optimize|backup|report|all}"
            echo ""
            echo "Commands:"
            echo "  health   - æ‰§è¡Œæ•°æ®åº“å¥åº·æ£€æŸ¥"
            echo "  optimize - æ‰§è¡Œæ€§èƒ½ä¼˜åŒ–"
            echo "  backup   - å¤‡ä»½æ•°æ®åº“"
            echo "  report   - ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"
            echo "  all      - æ‰§è¡Œæ‰€æœ‰æ“ä½œ"
            exit 1
            ;;
    esac
}

main "$@"
```

è¿™ä¸ªå®Œæ•´çš„æ•°æ®åº“æ€§èƒ½ä¼˜åŒ–æ–¹æ¡ˆæ¶µç›–äº†å¤åˆç´¢å¼•ç­–ç•¥ã€åˆ†åŒºå½’æ¡£ã€æ…¢æŸ¥è¯¢ç›‘æ§ã€è¿æ¥æ± ä¼˜åŒ–ã€è¯»å†™åˆ†ç¦»æ¶æ„ã€æ€§èƒ½ç›‘æ§å‘Šè­¦å’Œè¿ç»´å·¥å…·ï¼Œä¸ºç³»ç»Ÿæä¾›äº†å…¨é¢çš„æ•°æ®åº“æ€§èƒ½ä¿éšœã€‚
