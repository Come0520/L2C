# ç½—è±L2Cé”€å”®ç®¡ç†ç³»ç»Ÿ - Dockerå®¹å™¨åŒ–å’ŒKuberneteséƒ¨ç½²æ–¹æ¡ˆ

## ğŸ“‹ æ–‡æ¡£æ¦‚è¿°

**é¡¹ç›®åç§°ï¼š** ç½—è±L2Cé”€å”®ç®¡ç†ç³»ç»Ÿå®¹å™¨åŒ–éƒ¨ç½²æ–¹æ¡ˆ  
**æ–‡æ¡£ç‰ˆæœ¬ï¼š** v1.0  
**åˆ›å»ºæ—¥æœŸï¼š** 2024å¹´  
**è®¾è®¡ç›®æ ‡ï¼š** æ„å»ºé«˜å¯ç”¨ã€å¯æ‰©å±•ã€æ˜“ç»´æŠ¤çš„å®¹å™¨åŒ–éƒ¨ç½²æ¶æ„  

---

## ğŸ¯ éƒ¨ç½²ç›®æ ‡ä¸ä»·å€¼

### 1. æ ¸å¿ƒç›®æ ‡
- **ç¯å¢ƒä¸€è‡´æ€§**ï¼šå¼€å‘ã€æµ‹è¯•ã€ç”Ÿäº§ç¯å¢ƒå®Œå…¨ä¸€è‡´
- **å¿«é€Ÿéƒ¨ç½²**ï¼šæ”¯æŒå¿«é€Ÿéƒ¨ç½²å’Œå›æ»š
- **å¼¹æ€§ä¼¸ç¼©**ï¼šæ ¹æ®è´Ÿè½½è‡ªåŠ¨æ‰©ç¼©å®¹
- **é«˜å¯ç”¨æ€§**ï¼š99.9%ç³»ç»Ÿå¯ç”¨æ€§ä¿éšœ
- **èµ„æºä¼˜åŒ–**ï¼šåˆç†åˆ©ç”¨è®¡ç®—èµ„æºï¼Œé™ä½æˆæœ¬

### 2. æŠ€æœ¯æ¶æ„
- **å®¹å™¨åŒ–**ï¼šDocker + Docker Compose
- **ç¼–æ’å¹³å°**ï¼šKubernetes (K8s)
- **æœåŠ¡ç½‘æ ¼**ï¼šIstioï¼ˆå¯é€‰ï¼‰
- **ç›‘æ§ä½“ç³»**ï¼šPrometheus + Grafana
- **æ—¥å¿—æ”¶é›†**ï¼šELK Stack
- **é•œåƒä»“åº“**ï¼šHarbor

---

## ğŸ³ Dockerå®¹å™¨åŒ–è®¾è®¡

### 1. åº”ç”¨å®¹å™¨åŒ–

#### 1.1 å‰ç«¯åº”ç”¨å®¹å™¨åŒ–
```dockerfile
# frontend/Dockerfile
FROM node:18-alpine AS builder

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å¤åˆ¶packageæ–‡ä»¶
COPY package*.json ./
COPY yarn.lock ./

# å®‰è£…ä¾èµ–
RUN yarn install --frozen-lockfile

# å¤åˆ¶æºä»£ç 
COPY . .

# æ„å»ºåº”ç”¨
RUN yarn build

# ç”Ÿäº§ç¯å¢ƒé•œåƒ
FROM nginx:alpine

# å¤åˆ¶æ„å»ºäº§ç‰©
COPY --from=builder /app/dist /usr/share/nginx/html

# å¤åˆ¶nginxé…ç½®
COPY nginx.conf /etc/nginx/nginx.conf

# æš´éœ²ç«¯å£
EXPOSE 80

# å¯åŠ¨å‘½ä»¤
CMD ["nginx", "-g", "daemon off;"]
```

#### 1.2 åç«¯åº”ç”¨å®¹å™¨åŒ–
```dockerfile
# backend/Dockerfile
FROM node:18-alpine AS builder

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å¤åˆ¶packageæ–‡ä»¶
COPY package*.json ./
COPY yarn.lock ./

# å®‰è£…ä¾èµ–
RUN yarn install --frozen-lockfile

# å¤åˆ¶æºä»£ç 
COPY . .

# æ„å»ºåº”ç”¨
RUN yarn build

# ç”Ÿäº§ç¯å¢ƒé•œåƒ
FROM node:18-alpine

# åˆ›å»ºåº”ç”¨ç”¨æˆ·
RUN addgroup -g 1001 -S nodejs
RUN adduser -S nextjs -u 1001

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å¤åˆ¶æ„å»ºäº§ç‰©
COPY --from=builder --chown=nextjs:nodejs /app/dist ./dist
COPY --from=builder --chown=nextjs:nodejs /app/node_modules ./node_modules
COPY --from=builder --chown=nextjs:nodejs /app/package.json ./package.json

# åˆ‡æ¢ç”¨æˆ·
USER nextjs

# æš´éœ²ç«¯å£
EXPOSE 3000

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:3000/health || exit 1

# å¯åŠ¨å‘½ä»¤
CMD ["node", "dist/main.js"]
```

#### 1.3 æ•°æ®åº“å®¹å™¨åŒ–
```dockerfile
# database/Dockerfile
FROM postgres:15-alpine

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV POSTGRES_DB=crm_db
ENV POSTGRES_USER=postgres
ENV POSTGRES_PASSWORD=postgres

# å¤åˆ¶åˆå§‹åŒ–è„šæœ¬
COPY init-scripts/ /docker-entrypoint-initdb.d/

# å¤åˆ¶é…ç½®æ–‡ä»¶
COPY postgresql.conf /etc/postgresql/postgresql.conf
COPY pg_hba.conf /etc/postgresql/pg_hba.conf

# æš´éœ²ç«¯å£
EXPOSE 5432

# æ•°æ®å·
VOLUME ["/var/lib/postgresql/data"]
```

### 2. Docker Composeé…ç½®

#### 2.1 å¼€å‘ç¯å¢ƒé…ç½®
```yaml
# docker-compose.dev.yml
version: '3.8'

services:
  # å‰ç«¯æœåŠ¡
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.dev
    ports:
      - "3000:3000"
    volumes:
      - ./frontend:/app
      - /app/node_modules
    environment:
      - NODE_ENV=development
      - REACT_APP_API_URL=http://localhost:4000
    depends_on:
      - backend

  # åç«¯æœåŠ¡
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile.dev
    ports:
      - "4000:4000"
    volumes:
      - ./backend:/app
      - /app/node_modules
    environment:
      - NODE_ENV=development
      - DATABASE_URL=postgresql://postgres:postgres@postgres:5432/crm_db
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis

  # æ•°æ®åº“æœåŠ¡
  postgres:
    image: postgres:15-alpine
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_DB=crm_db
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/init-scripts:/docker-entrypoint-initdb.d

  # Redisç¼“å­˜
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes

  # Elasticsearch
  elasticsearch:
    image: elasticsearch:8.8.0
    ports:
      - "9200:9200"
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data

volumes:
  postgres_data:
  redis_data:
  elasticsearch_data:
```

#### 2.2 ç”Ÿäº§ç¯å¢ƒé…ç½®
```yaml
# docker-compose.prod.yml
version: '3.8'

services:
  # å‰ç«¯æœåŠ¡
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "80:80"
    environment:
      - NODE_ENV=production
    restart: unless-stopped
    depends_on:
      - backend

  # åç«¯æœåŠ¡
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - JWT_SECRET=${JWT_SECRET}
    restart: unless-stopped
    depends_on:
      - postgres
      - redis

  # æ•°æ®åº“æœåŠ¡
  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/backup:/backup
    restart: unless-stopped

  # Redisç¼“å­˜
  redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data
    restart: unless-stopped
    command: redis-server --appendonly yes

  # Nginxè´Ÿè½½å‡è¡¡
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
    depends_on:
      - frontend
      - backend
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:
```

### 3. é•œåƒä¼˜åŒ–ç­–ç•¥

#### 3.1 å¤šé˜¶æ®µæ„å»ºä¼˜åŒ–
```dockerfile
# ä¼˜åŒ–åçš„åç«¯Dockerfile
FROM node:18-alpine AS dependencies
WORKDIR /app
COPY package*.json yarn.lock ./
RUN yarn install --frozen-lockfile --production

FROM node:18-alpine AS builder
WORKDIR /app
COPY package*.json yarn.lock ./
RUN yarn install --frozen-lockfile
COPY . .
RUN yarn build

FROM node:18-alpine AS runtime
RUN addgroup -g 1001 -S nodejs
RUN adduser -S nextjs -u 1001

WORKDIR /app

# åªå¤åˆ¶å¿…è¦æ–‡ä»¶
COPY --from=dependencies --chown=nextjs:nodejs /app/node_modules ./node_modules
COPY --from=builder --chown=nextjs:nodejs /app/dist ./dist
COPY --from=builder --chown=nextjs:nodejs /app/package.json ./package.json

USER nextjs
EXPOSE 3000

# ä¼˜åŒ–çš„å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD wget --no-verbose --tries=1 --spider http://localhost:3000/health || exit 1

CMD ["node", "dist/main.js"]
```

#### 3.2 é•œåƒå®‰å…¨é…ç½®
```dockerfile
# å®‰å…¨ä¼˜åŒ–çš„Dockerfile
FROM node:18-alpine

# æ›´æ–°ç³»ç»ŸåŒ…
RUN apk update && apk upgrade && apk add --no-cache dumb-init

# åˆ›å»ºérootç”¨æˆ·
RUN addgroup -g 1001 -S nodejs && \
    adduser -S nextjs -u 1001 -G nodejs

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å¤åˆ¶åº”ç”¨æ–‡ä»¶
COPY --chown=nextjs:nodejs . .

# å®‰è£…ä¾èµ–
RUN yarn install --frozen-lockfile --production && \
    yarn cache clean

# ç§»é™¤ä¸å¿…è¦çš„åŒ…
RUN apk del .build-deps

# åˆ‡æ¢åˆ°érootç”¨æˆ·
USER nextjs

# ä½¿ç”¨dumb-initä½œä¸ºPID 1
ENTRYPOINT ["dumb-init", "--"]
CMD ["node", "dist/main.js"]
```

---

## â˜¸ï¸ Kuberneteséƒ¨ç½²é…ç½®

### 1. å‘½åç©ºé—´å’Œèµ„æºé…ç½®

#### 1.1 å‘½åç©ºé—´å®šä¹‰
```yaml
# k8s/namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: crm-system
  labels:
    name: crm-system
    environment: production
---
apiVersion: v1
kind: Namespace
metadata:
  name: crm-system-staging
  labels:
    name: crm-system-staging
    environment: staging
```

#### 1.2 ConfigMapé…ç½®
```yaml
# k8s/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: crm-config
  namespace: crm-system
data:
  NODE_ENV: "production"
  LOG_LEVEL: "info"
  API_VERSION: "v1"
  CORS_ORIGIN: "https://crm.luolai.com"
  SESSION_TIMEOUT: "3600"
  
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-config
  namespace: crm-system
data:
  nginx.conf: |
    upstream backend {
        server crm-backend:3000;
    }
    
    server {
        listen 80;
        server_name crm.luolai.com;
        
        location / {
            root /usr/share/nginx/html;
            try_files $uri $uri/ /index.html;
        }
        
        location /api {
            proxy_pass http://backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
    }
```

#### 1.3 Secreté…ç½®
```yaml
# k8s/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: crm-secrets
  namespace: crm-system
type: Opaque
data:
  DATABASE_URL: cG9zdGdyZXNxbDovL3VzZXI6cGFzc3dvcmRAcG9zdGdyZXM6NTQzMi9jcm1fZGI=
  JWT_SECRET: bXlfc3VwZXJfc2VjcmV0X2p3dF9rZXk=
  REDIS_PASSWORD: cmVkaXNfcGFzc3dvcmQ=
  
---
apiVersion: v1
kind: Secret
metadata:
  name: tls-secret
  namespace: crm-system
type: kubernetes.io/tls
data:
  tls.crt: LS0tLS1CRUdJTi... # base64ç¼–ç çš„è¯ä¹¦
  tls.key: LS0tLS1CRUdJTi... # base64ç¼–ç çš„ç§é’¥
```

### 2. åº”ç”¨éƒ¨ç½²é…ç½®

#### 2.1 åç«¯æœåŠ¡éƒ¨ç½²
```yaml
# k8s/backend-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: crm-backend
  namespace: crm-system
  labels:
    app: crm-backend
    version: v1
spec:
  replicas: 3
  selector:
    matchLabels:
      app: crm-backend
  template:
    metadata:
      labels:
        app: crm-backend
        version: v1
    spec:
      containers:
      - name: backend
        image: harbor.luolai.com/crm/backend:latest
        ports:
        - containerPort: 3000
        env:
        - name: NODE_ENV
          valueFrom:
            configMapKeyRef:
              name: crm-config
              key: NODE_ENV
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: crm-secrets
              key: DATABASE_URL
        - name: JWT_SECRET
          valueFrom:
            secretKeyRef:
              name: crm-secrets
              key: JWT_SECRET
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 3000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 3000
          initialDelaySeconds: 5
          periodSeconds: 5
        volumeMounts:
        - name: logs
          mountPath: /app/logs
      volumes:
      - name: logs
        emptyDir: {}
      
---
apiVersion: v1
kind: Service
metadata:
  name: crm-backend
  namespace: crm-system
spec:
  selector:
    app: crm-backend
  ports:
  - port: 3000
    targetPort: 3000
  type: ClusterIP
```

#### 2.2 å‰ç«¯æœåŠ¡éƒ¨ç½²
```yaml
# k8s/frontend-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: crm-frontend
  namespace: crm-system
  labels:
    app: crm-frontend
    version: v1
spec:
  replicas: 2
  selector:
    matchLabels:
      app: crm-frontend
  template:
    metadata:
      labels:
        app: crm-frontend
        version: v1
    spec:
      containers:
      - name: frontend
        image: harbor.luolai.com/crm/frontend:latest
        ports:
        - containerPort: 80
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
        livenessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 5
          periodSeconds: 5
        volumeMounts:
        - name: nginx-config
          mountPath: /etc/nginx/nginx.conf
          subPath: nginx.conf
      volumes:
      - name: nginx-config
        configMap:
          name: nginx-config

---
apiVersion: v1
kind: Service
metadata:
  name: crm-frontend
  namespace: crm-system
spec:
  selector:
    app: crm-frontend
  ports:
  - port: 80
    targetPort: 80
  type: ClusterIP
```

#### 2.3 æ•°æ®åº“éƒ¨ç½²ï¼ˆStatefulSetï¼‰
```yaml
# k8s/postgres-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
  namespace: crm-system
spec:
  serviceName: postgres
  replicas: 1
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
      - name: postgres
        image: postgres:15-alpine
        ports:
        - containerPort: 5432
        env:
        - name: POSTGRES_DB
          value: "crm_db"
        - name: POSTGRES_USER
          value: "postgres"
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: postgres-secret
              key: password
        - name: PGDATA
          value: /var/lib/postgresql/data/pgdata
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        volumeMounts:
        - name: postgres-storage
          mountPath: /var/lib/postgresql/data
        livenessProbe:
          exec:
            command:
            - pg_isready
            - -U
            - postgres
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          exec:
            command:
            - pg_isready
            - -U
            - postgres
          initialDelaySeconds: 5
          periodSeconds: 5
  volumeClaimTemplates:
  - metadata:
      name: postgres-storage
    spec:
      accessModes: ["ReadWriteOnce"]
      storageClassName: "fast-ssd"
      resources:
        requests:
          storage: 20Gi

---
apiVersion: v1
kind: Service
metadata:
  name: postgres
  namespace: crm-system
spec:
  selector:
    app: postgres
  ports:
  - port: 5432
    targetPort: 5432
  type: ClusterIP
```

### 3. è‡ªåŠ¨æ‰©ç¼©å®¹é…ç½®

#### 3.1 HPAé…ç½®
```yaml
# k8s/hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: crm-backend-hpa
  namespace: crm-system
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: crm-backend
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60

---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: crm-frontend-hpa
  namespace: crm-system
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: crm-frontend
  minReplicas: 2
  maxReplicas: 5
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 60
```

#### 3.2 VPAé…ç½®
```yaml
# k8s/vpa.yaml
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: crm-backend-vpa
  namespace: crm-system
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: crm-backend
  updatePolicy:
    updateMode: "Auto"
  resourcePolicy:
    containerPolicies:
    - containerName: backend
      minAllowed:
        cpu: 100m
        memory: 128Mi
      maxAllowed:
        cpu: 1000m
        memory: 1Gi
      controlledResources: ["cpu", "memory"]
```

### 4. ç½‘ç»œå’Œå®‰å…¨é…ç½®

#### 4.1 Ingressé…ç½®
```yaml
# k8s/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: crm-ingress
  namespace: crm-system
  annotations:
    kubernetes.io/ingress.class: "nginx"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/use-regex: "true"
    nginx.ingress.kubernetes.io/rewrite-target: /$1
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
spec:
  tls:
  - hosts:
    - crm.luolai.com
    secretName: tls-secret
  rules:
  - host: crm.luolai.com
    http:
      paths:
      - path: /api/(.*)
        pathType: Prefix
        backend:
          service:
            name: crm-backend
            port:
              number: 3000
      - path: /(.*)
        pathType: Prefix
        backend:
          service:
            name: crm-frontend
            port:
              number: 80
```

#### 4.2 ç½‘ç»œç­–ç•¥
```yaml
# k8s/network-policy.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: crm-network-policy
  namespace: crm-system
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: ingress-nginx
    - podSelector:
        matchLabels:
          app: crm-frontend
    - podSelector:
        matchLabels:
          app: crm-backend
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: postgres
    ports:
    - protocol: TCP
      port: 5432
  - to:
    - podSelector:
        matchLabels:
          app: redis
    ports:
    - protocol: TCP
      port: 6379
  - to: []
    ports:
    - protocol: TCP
      port: 53
    - protocol: UDP
      port: 53
```

### 5. ç›‘æ§å’Œæ—¥å¿—é…ç½®

#### 5.1 Prometheusç›‘æ§
```yaml
# k8s/monitoring.yaml
apiVersion: v1
kind: ServiceMonitor
metadata:
  name: crm-backend-monitor
  namespace: crm-system
  labels:
    app: crm-backend
spec:
  selector:
    matchLabels:
      app: crm-backend
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics

---
apiVersion: v1
kind: Service
metadata:
  name: crm-backend-metrics
  namespace: crm-system
  labels:
    app: crm-backend
spec:
  selector:
    app: crm-backend
  ports:
  - name: metrics
    port: 9090
    targetPort: 9090
```

#### 5.2 æ—¥å¿—æ”¶é›†é…ç½®
```yaml
# k8s/logging.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluent-bit-config
  namespace: crm-system
data:
  fluent-bit.conf: |
    [SERVICE]
        Flush         1
        Log_Level     info
        Daemon        off
        Parsers_File  parsers.conf
        HTTP_Server   On
        HTTP_Listen   0.0.0.0
        HTTP_Port     2020

    [INPUT]
        Name              tail
        Path              /var/log/containers/*crm*.log
        Parser            docker
        Tag               kube.*
        Refresh_Interval  5
        Mem_Buf_Limit     50MB
        Skip_Long_Lines   On

    [OUTPUT]
        Name  es
        Match *
        Host  elasticsearch.logging.svc.cluster.local
        Port  9200
        Index crm-logs
        Type  _doc
```

---

## ğŸš€ éƒ¨ç½²æµç¨‹å’Œè„šæœ¬

### 1. éƒ¨ç½²è„šæœ¬

#### 1.1 ä¸€é”®éƒ¨ç½²è„šæœ¬
```bash
#!/bin/bash
# deploy.sh - ä¸€é”®éƒ¨ç½²è„šæœ¬

set -e

# é…ç½®å˜é‡
NAMESPACE="crm-system"
ENVIRONMENT=${1:-production}
IMAGE_TAG=${2:-latest}
REGISTRY="harbor.luolai.com/crm"

echo "ğŸš€ å¼€å§‹éƒ¨ç½² CRM ç³»ç»Ÿåˆ° $ENVIRONMENT ç¯å¢ƒ"

# æ£€æŸ¥kubectlè¿æ¥
if ! kubectl cluster-info > /dev/null 2>&1; then
    echo "âŒ æ— æ³•è¿æ¥åˆ° Kubernetes é›†ç¾¤"
    exit 1
fi

# åˆ›å»ºå‘½åç©ºé—´
echo "ğŸ“¦ åˆ›å»ºå‘½åç©ºé—´..."
kubectl apply -f k8s/namespace.yaml

# åº”ç”¨é…ç½®
echo "âš™ï¸  åº”ç”¨é…ç½®æ–‡ä»¶..."
kubectl apply -f k8s/configmap.yaml
kubectl apply -f k8s/secret.yaml

# éƒ¨ç½²æ•°æ®åº“
echo "ğŸ—„ï¸  éƒ¨ç½²æ•°æ®åº“..."
kubectl apply -f k8s/postgres-statefulset.yaml

# ç­‰å¾…æ•°æ®åº“å°±ç»ª
echo "â³ ç­‰å¾…æ•°æ®åº“å°±ç»ª..."
kubectl wait --for=condition=ready pod -l app=postgres -n $NAMESPACE --timeout=300s

# éƒ¨ç½²Redis
echo "ğŸ”´ éƒ¨ç½²Redis..."
kubectl apply -f k8s/redis-deployment.yaml

# éƒ¨ç½²åç«¯æœåŠ¡
echo "ğŸ”§ éƒ¨ç½²åç«¯æœåŠ¡..."
sed "s|{{IMAGE_TAG}}|$IMAGE_TAG|g" k8s/backend-deployment.yaml | kubectl apply -f -

# ç­‰å¾…åç«¯æœåŠ¡å°±ç»ª
echo "â³ ç­‰å¾…åç«¯æœåŠ¡å°±ç»ª..."
kubectl wait --for=condition=ready pod -l app=crm-backend -n $NAMESPACE --timeout=300s

# éƒ¨ç½²å‰ç«¯æœåŠ¡
echo "ğŸ¨ éƒ¨ç½²å‰ç«¯æœåŠ¡..."
sed "s|{{IMAGE_TAG}}|$IMAGE_TAG|g" k8s/frontend-deployment.yaml | kubectl apply -f -

# éƒ¨ç½²Ingress
echo "ğŸŒ é…ç½®Ingress..."
kubectl apply -f k8s/ingress.yaml

# é…ç½®è‡ªåŠ¨æ‰©ç¼©å®¹
echo "ğŸ“ˆ é…ç½®è‡ªåŠ¨æ‰©ç¼©å®¹..."
kubectl apply -f k8s/hpa.yaml

# é…ç½®ç›‘æ§
echo "ğŸ“Š é…ç½®ç›‘æ§..."
kubectl apply -f k8s/monitoring.yaml

# æ£€æŸ¥éƒ¨ç½²çŠ¶æ€
echo "ğŸ” æ£€æŸ¥éƒ¨ç½²çŠ¶æ€..."
kubectl get pods -n $NAMESPACE
kubectl get services -n $NAMESPACE
kubectl get ingress -n $NAMESPACE

echo "âœ… éƒ¨ç½²å®Œæˆï¼"
echo "ğŸŒ è®¿é—®åœ°å€: https://crm.luolai.com"
```

#### 1.2 å›æ»šè„šæœ¬
```bash
#!/bin/bash
# rollback.sh - å›æ»šè„šæœ¬

set -e

NAMESPACE="crm-system"
REVISION=${1:-1}

echo "ğŸ”„ å¼€å§‹å›æ»šåˆ°ç‰ˆæœ¬ $REVISION"

# å›æ»šåç«¯æœåŠ¡
echo "ğŸ”§ å›æ»šåç«¯æœåŠ¡..."
kubectl rollout undo deployment/crm-backend -n $NAMESPACE --to-revision=$REVISION

# å›æ»šå‰ç«¯æœåŠ¡
echo "ğŸ¨ å›æ»šå‰ç«¯æœåŠ¡..."
kubectl rollout undo deployment/crm-frontend -n $NAMESPACE --to-revision=$REVISION

# ç­‰å¾…å›æ»šå®Œæˆ
echo "â³ ç­‰å¾…å›æ»šå®Œæˆ..."
kubectl rollout status deployment/crm-backend -n $NAMESPACE
kubectl rollout status deployment/crm-frontend -n $NAMESPACE

echo "âœ… å›æ»šå®Œæˆï¼"
```

#### 1.3 å¥åº·æ£€æŸ¥è„šæœ¬
```bash
#!/bin/bash
# health-check.sh - å¥åº·æ£€æŸ¥è„šæœ¬

NAMESPACE="crm-system"
BACKEND_URL="https://crm.luolai.com/api/health"
FRONTEND_URL="https://crm.luolai.com"

echo "ğŸ¥ å¼€å§‹å¥åº·æ£€æŸ¥..."

# æ£€æŸ¥PodçŠ¶æ€
echo "ğŸ“¦ æ£€æŸ¥PodçŠ¶æ€..."
kubectl get pods -n $NAMESPACE

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
echo "ğŸ”§ æ£€æŸ¥æœåŠ¡çŠ¶æ€..."
kubectl get services -n $NAMESPACE

# æ£€æŸ¥åç«¯å¥åº·çŠ¶æ€
echo "ğŸ” æ£€æŸ¥åç«¯å¥åº·çŠ¶æ€..."
if curl -f $BACKEND_URL > /dev/null 2>&1; then
    echo "âœ… åç«¯æœåŠ¡å¥åº·"
else
    echo "âŒ åç«¯æœåŠ¡å¼‚å¸¸"
fi

# æ£€æŸ¥å‰ç«¯å¥åº·çŠ¶æ€
echo "ğŸ” æ£€æŸ¥å‰ç«¯å¥åº·çŠ¶æ€..."
if curl -f $FRONTEND_URL > /dev/null 2>&1; then
    echo "âœ… å‰ç«¯æœåŠ¡å¥åº·"
else
    echo "âŒ å‰ç«¯æœåŠ¡å¼‚å¸¸"
fi

# æ£€æŸ¥èµ„æºä½¿ç”¨æƒ…å†µ
echo "ğŸ“Š æ£€æŸ¥èµ„æºä½¿ç”¨æƒ…å†µ..."
kubectl top pods -n $NAMESPACE

echo "ğŸ¥ å¥åº·æ£€æŸ¥å®Œæˆï¼"
```

### 2. CI/CDé›†æˆ

#### 2.1 GitLab CIé…ç½®
```yaml
# .gitlab-ci.yml
stages:
  - build
  - test
  - deploy

variables:
  DOCKER_REGISTRY: harbor.luolai.com
  PROJECT_NAME: crm
  KUBECONFIG: /etc/deploy/config

build:
  stage: build
  script:
    - docker build -t $DOCKER_REGISTRY/$PROJECT_NAME/backend:$CI_COMMIT_SHA ./backend
    - docker build -t $DOCKER_REGISTRY/$PROJECT_NAME/frontend:$CI_COMMIT_SHA ./frontend
    - docker push $DOCKER_REGISTRY/$PROJECT_NAME/backend:$CI_COMMIT_SHA
    - docker push $DOCKER_REGISTRY/$PROJECT_NAME/frontend:$CI_COMMIT_SHA
  only:
    - main
    - develop

test:
  stage: test
  script:
    - npm test
    - npm run test:e2e
  only:
    - main
    - develop

deploy_staging:
  stage: deploy
  script:
    - ./scripts/deploy.sh staging $CI_COMMIT_SHA
  environment:
    name: staging
    url: https://crm-staging.luolai.com
  only:
    - develop

deploy_production:
  stage: deploy
  script:
    - ./scripts/deploy.sh production $CI_COMMIT_SHA
  environment:
    name: production
    url: https://crm.luolai.com
  when: manual
  only:
    - main
```

è¿™ä¸ªå®Œæ•´çš„Dockerå®¹å™¨åŒ–å’ŒKuberneteséƒ¨ç½²æ–¹æ¡ˆæä¾›äº†ä»å¼€å‘åˆ°ç”Ÿäº§çš„å…¨æµç¨‹å®¹å™¨åŒ–è§£å†³æ–¹æ¡ˆï¼Œç¡®ä¿ç³»ç»Ÿçš„é«˜å¯ç”¨æ€§ã€å¯æ‰©å±•æ€§å’Œæ˜“ç»´æŠ¤æ€§ã€‚
